---
title: "Self Evaluation Project"
author: "Andy"
date: "3/15/2022"
output: html_document
---

```{r}
library(tidyverse)
library(gridExtra)
```

<br>  


## Read Data & Manipulation

```{r}

all_dat = read.csv('/Volumes/Programming/Spring 2022/project/all_dat.csv')
# all_dat = read.csv('D:/Spring 2022/Project/all_dat.csv')
morning_rt = read.csv('/Volumes/Programming/personal/progress/morning_routine.csv')


colnames(all_dat) <- c('X', 'Name','Finished','Multiple','Phone_pickups',
                       'Screen_time','Created','Date','Drink','Key_words',
                       'Meditation','Mentality','Satisfaction',
                       'Reading','Productivity','Rise_time','Run','Social',
                       'Tech','Total','Total_todo','Work_done')

# Remove unnecessary columns & Modify some columns
all_dat <- all_dat %>%
  dplyr::select(Date, everything(), Finished, Total_todo,-X,-Name,-Created, - Work_done) %>%
  mutate(work_finished = round(Finished/Total_todo,4),
         Drink = lag(Drink),
         Tot_diff = lag(Total)-Total) %>% # Make a work_finished variable
              # we lag(shift by 1) because we want the day after
  tibble()
  
# Same for morning routine
morning_rt <- morning_rt %>%
  dplyr::select(Date, everything(), -X,-level_0,-index) %>%
  mutate(Date = strptime(as.character(morning_rt$Date), "%m/%d/%Y"),
         Date = format(Date, "%m/%d/%Y")) %>%
  tibble()

# merge morning_rt with all_dat
all_morning_rt <- merge(morning_rt, all_dat,by="Date", all.x=T) %>%
  arrange(desc(Date))


# Drop Name & Created column
dat_date =  filter(all_dat, Date!=0) # Exclude wrong date format

# Only include multiple-related(social, tech, satisfaction, overall, etc)
  # Multiple data length: 53
multiple_dat = filter(all_dat, Productivity!=0)

all_dat
```

  
<br>  


## Visualization

```{r, echo = TRUE, eval = TRUE, out.width = "1600px", fig.width = 12, fig.height = 6, fig.asp = .75, fig.align='center'}

p1 <- ggplot(data = all_dat, alpha=.5) + 
  geom_density( aes(Total), color = 'red')

p2 <- ggplot(data = all_dat) +
  geom_density( aes(work_finished), color = 'blue')

p3 <- ggplot(data = all_dat, alpha=.5)+
  geom_density( aes(Reading), color = 'purple')

p4 <-ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Meditation), color = 'black')

p5 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Phone_pickups), color = 'green')

p6 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Screen_time), color = 'orange')

p7 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Rise_time), color = 'skyblue')

p8 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Drink), color = 'darkgreen')
  
grid.arrange(p1, p2, p3,p4,p5,p6,p7,p8, nrow = 4)

#ggplot(data = all_morning_rt)+
  #geom_bar(aes(morning_thoughts_check, fill = push_up_check))
```

  
<br>  


## Linear Regression

```{r, echo=FALSE}

# Click below to see more about lm() summary function
# https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/#:~:text=Summary%20in%20R-,Explaining%20the%20lm()%20Summary%20in%20R,the%20error%20of%20the%20model.

meditation_all <- lm(Meditation ~ Multiple+ Phone_pickups+ Screen_time+ Drink+
                       Reading+ Rise_time+ Total_todo + Total + work_finished, 
                     data = all_dat)
summary(meditation_all)

# Multiple data length: 53
multiple_tail <- lm(Multiple ~ Phone_pickups+ Screen_time+ Drink+ Meditation+
                      Reading+ Rise_time+ Total_todo + 
                      work_finished + Total, 
                    data = multiple_dat)
summary(multiple_tail)

# Multiple data all
multiple_all <- lm(Multiple ~ Phone_pickups+ Screen_time+ Drink+ Meditation+
                     Reading+ Rise_time+ Run + Total_todo + Total , 
                   data = all_dat)
summary(multiple_all)


```

  
<br>  


## Linear Regression Summary for Work_done (all_dat)

```{r}
#################### Linear Regression Work_done (all_dat) #####################

# Work done 
work_finished_all <- lm(work_finished ~ Multiple + Phone_pickups + Screen_time + 
                          Drink + Meditation + Reading + Rise_time + Run + 
                          Total_todo,
                        data = all_dat)
summary(work_finished_all)
```
  
<br>  


## Actual vs Prediction Visualization for Work_done (all_dat)

```{r}
all_dat$pred_work_finished <- predict(work_finished_all, newdata = all_dat)

# Explanatory variable: work_finished
ggplot(data = all_dat, aes(x = pred_work_finished, y = work_finished)) +
  geom_point(alpha = 0.5, color = "darkgray") +
  geom_smooth(color = "darkblue") +
  geom_line(aes(x = work_finished,
                y = work_finished),   # Plotting the line, y = x
            color = "red", linetype = 2) +
  coord_cartesian( xlim = c(0, 1),
                   ylim = c(0, 1) )  # Limits the range of the

```
  
<br>  


## Actual vs Prediction Residual Visualization for Work_done (all_dat)

```{r}
# graph for legibility# Plot of residual error as a function of prediction
ggplot(data = all_dat, aes(x = pred_work_finished,
                           y = pred_work_finished - work_finished)) +
  geom_point(alpha = 0.2, color = "darkgray") +
  geom_smooth(color = "darkblue") +
  geom_line(aes(x = pred_work_finished,
                y = 0),   # Plotting the line, y = 0
            color = "red", linetype = 2) +
  ylab("residual error (prediction - actual)")

```

<br>  


## Testing Normality

```{r}
################################## Normality ##################################
library(dplyr)
set.seed(1234)
dplyr::sample_n(all_dat, 10)

# The central limit theorem tells us that no matter what distribution things 
# have, the sampling distribution tends to be normal if the sample is large 
# enough (n > 30).

# The R function shapiro.test() can be used to perform the Shapiro-Wilk test 
# of normality for one variable (univariate):

shapiro.test(all_dat$Total)

```
<br>  

  
  
##  Determining Distributions  
* Multiple(fit.normal)

```{r}

library(fitdistrplus)
library(logspline)

# The kurtosis and squared skewness of your sample is plotted as a blue point 
# named "Observation".
descdist(all_dat$Multiple, discrete = FALSE)
descdist(all_dat$Screen_time, discrete = FALSE)

wf <- c(na.omit(all_dat$work_finished))
descdist(wf, discrete = FALSE)

#fit.beta <- fitdist(wf, 'beta', method = "mme") 
  # method = "mme": Moment matching estimation consists in equalizing theoretical
  #                 and empirical moments. 
#fit.gamma <- fitdist(all_dat$Screen_time, "gamma")
fit.normal <- fitdist(all_dat$Multiple, "norm")
#plot(fit.beta)
#plot(fit.gamma)
plot(fit.normal)
```

