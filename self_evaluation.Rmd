---
title: "Self Evaluation Project"
author: "Andy"
date: "3/15/2022"
output: html_document
---

```{r, results='hide'}
library(lubridate)
library(gridExtra)
library(tidyverse)
library(margins)
library(psych)
```

<br>  


### Read Data & Manipulation

```{r}

all_dat = read.csv('/Volumes/Programming/Spring 2022/project/all_dat.csv')
# all_dat = read.csv('D:/Spring 2022/Project/all_dat.csv')
morning_rt = read.csv('/Volumes/Programming/Spring 2022/Project/morning_routine.csv')


colnames(all_dat) <- c('X', 'Name','Finished','Multiple','Phone_pickups',
                       'Screen_time','Created','Date','Drink','Key_words',
                       'Meditation','Mentality','Satisfaction',
                       'Reading','Productivity','Rise_time','Run','Social',
                       'Tech','Total','Total_todo','Work_done')

# Remove unnecessary columns & Modify some columns #new
all_dat <- all_dat %>%
  dplyr::select(Date, everything(), Finished, Total_todo,-X,-Name,-Created, - Work_done) %>%
  dplyr::mutate(work_finished = round(Finished/Total_todo,4),
         Drink = lag(Drink),
         Total = Total*100)%>%
  tibble()


# Same for morning routine #new
morning_rt <- morning_rt %>%
  dplyr::mutate(Date = strptime(as.character(morning_rt$Date), "%m/%d/%Y"),
         Date = format(Date, "%m/%d/%Y"),
         morning_phone = rise_time_check, # modify column name 
         night_phone = before_sleep_check) %>%
  dplyr::select(Date, everything(), -c(X, level_0, index, 
                                rise_time_check, before_sleep_check)) %>%
  tibble()

# merge morning_rt with all_dat
all_morning_rt <- merge(morning_rt, all_dat,by="Date", all.x=T) %>%
  dplyr::mutate(Date = mdy(Date),
         work_finished_mr_exc = 
           round((Finished-total_checked)/(Total_todo-6),4)) %>%
            # work_finished_mr_exc: this variable excludes morning routine 
            #         tasks for more accurate statistical analysis. 
  
  dplyr::select(-c(rise_time_min)) %>% # redundant
  dplyr::filter(work_finished_mr_exc <= 1 & work_finished_mr_exc >0) %>%
  arrange(desc(Date))


# Drop Name & Created column
dat_date =  filter(all_dat, Date!=0) # Exclude wrong date format

# Only include multiple-related(social, tech, satisfaction, overall, etc)
  # Multiple data length: 53
multiple_dat = filter(all_dat, Productivity!=0)

```

  
<br>  


### Distribution for the main variables

```{r, echo = TRUE, eval = TRUE, out.width = "1600px", fig.width = 9, fig.height = 5, fig.asp = .75, fig.align='center', warning = FALSE}

p1 <- ggplot(data = all_dat, alpha=.5) + 
  geom_density( aes(Total), color = 'red')

p2 <- ggplot(data = all_dat) +
  geom_density( aes(work_finished), color = 'blue')

p3 <- ggplot(data = all_dat, alpha=.5)+
  geom_density( aes(Reading), color = 'purple')

p4 <-ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Meditation), color = 'black')

p5 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Phone_pickups), color = 'green')

p6 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Screen_time), color = 'orange')

p7 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Rise_time), color = 'skyblue')

p8 <- ggplot(data = all_dat, alpha=.5)+
  geom_density(aes(Drink), color = 'darkgreen')
  
grid.arrange(p1, p2, p3,p4,p5,p6,p7,p8, nrow = 4)

```
<br>  
<br>  


## How do these variables affect the outcome of the day?

<br>  

### Find the relationships between these variables and how they affect my lifestyle

<br>  

<font size="3">We will first take a look at the characteristics of the variables by utilizing **descriptive statistics**.</font>
<br>  

* <font size="3">Use **pairs.panels function** in psych module
  + The *diagonal histograms* demonstrates the distribution of each variable 
  + The *bottom left triangle* represents a scatter plot with the best fit line
  + The *top right triangle* represents a correlation coefficient for each pair, which ranges from -1 to 1
      - If the coefficient is close to 1, it means that the pair holds a positive relationship and a negative relationship for -1. 
  + Correlation Coefficient Formula:</font>
$$r = \dfrac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}}$$



```{r, echo = TRUE, eval = TRUE, out.width = "1600px", fig.width = 9, fig.height = 5, fig.asp = .75, fig.align='center', warning = FALSE}
correlation_plot <- all_dat %>%
  select(c(Screen_time, Meditation, Multiple, Rise_time, work_finished, 
           Reading,Total))

pairs.panels(correlation_plot, lm = TRUE)
```

<br>  


#### Single Regression Function: $y=\alpha+\beta x$


* <font size = "3">Set:
  + y = 
  + x = 
  + $\alpha$ = y-intercept
  + $\beta$ = slope </font>

* <font size = "3">lm() function:Fitting Linear Models
  1. Finds fitted line($\alpha$ & $\beta$) by using the least-square method
      - **Least-square**: by summing up the residual squares for different curves, it finds the "least squared" curve that best fit the data. 
  2. Outputs $R^2$, p-value and other meaningful calculations
      - $R^2$: It demonstrates how accurate the fitted line is to the data
      - Formula: $R^2 = \dfrac{Var(mean)-Var(fit)}{Var(min)}$
      - Ex: If we get.8, it means that $x$ explains 60% of the variation in $y$</font>

<br>  


  
<br>  
<br>  


## How important is my Morning Routine? 

<br>  

### Test how many checked morning routines affect the outcome of the day
* <font size = "4">The morning routine tasks:
  + Not touching my phone for at least 30 minutes the night before
  + Not touching my phone for an hour after I wake up
  + Exercise 
  + Meditation
  + Reading
  + Morning journal </font>
```{r, collapse=TRUE, out.width = "1000px", figures-side, fig.asp = .75, fig.align='center', warning = FALSE}

# see how number of morning routine checks affects the Total %
ggplot(filter(all_morning_rt, total_checked != 0)) + 
  geom_density(aes(Total))+
  facet_wrap(~total_checked)+
  labs(title = "Morning Routine checked & \nTotal %")

# see how number of morning routine checks affects the total todo lists checked
ggplot(filter(all_morning_rt, total_checked != 0)) + 
  geom_density(aes(work_finished_mr_exc))+
  facet_wrap(~total_checked)+
  labs(title = "Morning Routine checked & \n todo lists finished(excluding morning routine tasks)")
```

<br>  


### Logistic Regression

<br>  


#### Single Logistic Regression
```{r, message=FALSE, warning=FALSE}
model_logit <- glm(work_finished_mr_exc ~ night_phone,
                   data = all_morning_rt, family = binomial(link = "logit"))
m = margins(model_logit) 
ame_result = summary(m) 
ame_result
```
<br>  

#### How to interpret the Average Marginal Effect(AME) values
* <font size = "3"> Interpret them as percentage points rather than percentage
  + work_finished  .1911 : Indicates that if I do not touch my phone the night before, I am 19.06 percentage point more likely to get more tasks done. </font>
<br>  

```{r}
ggplot(data = ame_result) +
  geom_point(aes(factor , AME)) +
  geom_errorbar(aes(x = factor, ymin = lower, ymax = upper),
  width = .5) + geom_hline ( yintercept = 0) +
  theme_minimal ( ) +
  theme(axis.text.x = element_text(angle = 90))
```



<br>  


#### Meditation with all_dat
```{r, echo=FALSE}

# Click below to see more about lm() summary function
# https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/#:~:text=Summary%20in%20R-,Explaining%20the%20lm()%20Summary%20in%20R,the%20error%20of%20the%20model.

meditation_all <- lm(Meditation ~ Multiple+ Phone_pickups+ Screen_time+ Drink+
                       Reading+ Rise_time+ Total_todo + Total + work_finished, 
                     data = all_dat)
summary(meditation_all)

```

<br>  

#### Multiple with multiple_dat
* Multiple data length: 50 + 
```{r}
multiple_tail <- lm(Multiple ~ Phone_pickups+ Screen_time+ Drink+ Meditation+
                      Reading+ Rise_time+ Total_todo + 
                      work_finished + Total, 
                    data = multiple_dat)
summary(multiple_tail)

```

<br>  

#### Multiple with all_dat
* Multiple data length: 450 + 
```{r}
# Multiple data all
multiple_all <- lm(Multiple ~ Phone_pickups+ Screen_time+ Drink+ Meditation+
                     Reading+ Rise_time+ Run + Total_todo + Total , 
                   data = all_dat)
summary(multiple_all)
```

  
<br>  


### Linear Regression Summary for Work_done (all_dat)

```{r}
#################### Linear Regression Work_done (all_dat) #####################

# Work done 
work_finished_all <- lm(work_finished ~ Multiple + Phone_pickups + Screen_time + 
                          Drink + Meditation + Reading + Rise_time + Run + 
                          Total_todo,
                        data = all_dat)
summary(work_finished_all)
```
  
<br>  


### Actual vs Prediction Visualization for Work_done (all_dat)

```{r, warning=FALSE}
all_dat$pred_work_finished <- predict(work_finished_all, newdata = all_dat)

# Explanatory variable: work_finished
ggplot(data = all_dat, aes(x = pred_work_finished, y = work_finished)) +
  geom_point(alpha = 0.5, color = "darkgray") +
  geom_smooth(color = "darkblue") +
  geom_line(aes(x = work_finished,
                y = work_finished),   # Plotting the line, y = x
            color = "red", linetype = 2) +
  coord_cartesian( xlim = c(0, 1),
                   ylim = c(0, 1) )  # Limits the range of the

```
  
<br>  


### Actual vs Prediction Residual Visualization for Work_done (all_dat)

```{r, warning=FALSE}
# graph for legibility# Plot of residual error as a function of prediction
ggplot(data = all_dat, aes(x = pred_work_finished,
                           y = pred_work_finished - work_finished)) +
  geom_point(alpha = 0.2, color = "darkgray") +
  geom_smooth(color = "darkblue") +
  geom_line(aes(x = pred_work_finished,
                y = 0),   # Plotting the line, y = 0
            color = "red", linetype = 2) +
  ylab("residual error (prediction - actual)")

```

<br>  


### Testing Normality

```{r}
library(dplyr)
set.seed(1234)
dplyr::sample_n(all_dat, 10)

# The central limit theorem tells us that no matter what distribution things 
# have, the sampling distribution tends to be normal if the sample is large 
# enough (n > 30).

# The R function shapiro.test() can be used to perform the Shapiro-Wilk test 
# of normality for one variable (univariate):

shapiro.test(all_dat$Total)

```
<br>  

  
  
###  Determining Distributions  
* Multiple(fit.normal)

```{r}

library(fitdistrplus)
library(logspline)

# The kurtosis and squared skewness of your sample is plotted as a blue point 
# named "Observation".
descdist(all_dat$Multiple, discrete = FALSE)
descdist(all_dat$Screen_time, discrete = FALSE)

wf <- c(na.omit(all_dat$work_finished))
descdist(wf, discrete = FALSE)

#fit.beta <- fitdist(wf, 'beta', method = "mme") 
  # method = "mme": Moment matching estimation consists in equalizing theoretical
  #                 and empirical moments. 
#fit.gamma <- fitdist(all_dat$Screen_time, "gamma")
fit.normal <- fitdist(all_dat$Multiple, "norm")
#plot(fit.beta)
#plot(fit.gamma)
plot(fit.normal)
```

